{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:51:00.442249900Z",
     "start_time": "2025-05-23T14:51:00.426628800Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(scores_dist) 62\n",
      "og len(scores) 90\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# From huggingface api, with our trained adapters (eu, sr)\n",
    "existing_adapters = [\n",
    "    \"th\",\n",
    "    \"my\",\n",
    "    \"hi\",\n",
    "    \"ilo\",\n",
    "    \"ht\",\n",
    "    \"tr\",\n",
    "    \"mi\",\n",
    "    \"vi\",\n",
    "    \"is\",\n",
    "    \"it\",\n",
    "    \"ta\",\n",
    "    \"jv\",\n",
    "    \"ja\",\n",
    "    \"sw\",\n",
    "    \"qu\",\n",
    "    \"de\",\n",
    "    \"el\",\n",
    "    \"et\",\n",
    "    \"ru\",\n",
    "    \"gn\",\n",
    "    \"id\",\n",
    "    \"en\",\n",
    "    \"ar\",\n",
    "    \"es\",\n",
    "    \"tk\",\n",
    "    \"zh\",\n",
    "    \"mhr\",\n",
    "    \"cdo\",\n",
    "    \"xmf\",\n",
    "    \"eu\",\n",
    "    \"sr\",\n",
    "]\n",
    "# scraped from cc-100 website\n",
    "xlm_included_langs = [\n",
    "    \"af\",\n",
    "    \"am\",\n",
    "    \"ar\",\n",
    "    \"as\",\n",
    "    \"az\",\n",
    "    \"be\",\n",
    "    \"bg\",\n",
    "    \"bn\",\n",
    "    \"br\",\n",
    "    \"bs\",\n",
    "    \"ca\",\n",
    "    \"cs\",\n",
    "    \"cy\",\n",
    "    \"da\",\n",
    "    \"de\",\n",
    "    \"el\",\n",
    "    \"en\",\n",
    "    \"eo\",\n",
    "    \"es\",\n",
    "    \"et\",\n",
    "    \"eu\",\n",
    "    \"fa\",\n",
    "    \"ff\",\n",
    "    \"fi\",\n",
    "    \"fr\",\n",
    "    \"fy\",\n",
    "    \"ga\",\n",
    "    \"gd\",\n",
    "    \"gl\",\n",
    "    \"gn\",\n",
    "    \"gu\",\n",
    "    \"ha\",\n",
    "    \"he\",\n",
    "    \"hi\",\n",
    "    \"hr\",\n",
    "    \"ht\",\n",
    "    \"hu\",\n",
    "    \"hy\",\n",
    "    \"id\",\n",
    "    \"ig\",\n",
    "    \"is\",\n",
    "    \"it\",\n",
    "    \"ja\",\n",
    "    \"jv\",\n",
    "    \"ka\",\n",
    "    \"kk\",\n",
    "    \"km\",\n",
    "    \"kn\",\n",
    "    \"ko\",\n",
    "    \"ku\",\n",
    "    \"ky\",\n",
    "    \"la\",\n",
    "    \"lg\",\n",
    "    \"li\",\n",
    "    \"ln\",\n",
    "    \"lo\",\n",
    "    \"lt\",\n",
    "    \"lv\",\n",
    "    \"mg\",\n",
    "    \"mk\",\n",
    "    \"ml\",\n",
    "    \"mn\",\n",
    "    \"mr\",\n",
    "    \"ms\",\n",
    "    \"my\",\n",
    "    \"ne\",\n",
    "    \"nl\",\n",
    "    \"no\",\n",
    "    \"ns\",\n",
    "    \"om\",\n",
    "    \"or\",\n",
    "    \"pa\",\n",
    "    \"pl\",\n",
    "    \"ps\",\n",
    "    \"pt\",\n",
    "    \"qu\",\n",
    "    \"rm\",\n",
    "    \"ro\",\n",
    "    \"ru\",\n",
    "    \"sa\",\n",
    "    \"si\",\n",
    "    \"sc\",\n",
    "    \"sd\",\n",
    "    \"sk\",\n",
    "    \"sl\",\n",
    "    \"so\",\n",
    "    \"sq\",\n",
    "    \"sr\",\n",
    "    \"ss\",\n",
    "    \"su\",\n",
    "    \"sv\",\n",
    "    \"sw\",\n",
    "    \"ta\",\n",
    "    \"te\",\n",
    "    \"th\",\n",
    "    \"tl\",\n",
    "    \"tn\",\n",
    "    \"tr\",\n",
    "    \"ug\",\n",
    "    \"uk\",\n",
    "    \"ur\",\n",
    "    \"uz\",\n",
    "    \"vi\",\n",
    "    \"wo\",\n",
    "    \"xh\",\n",
    "    \"yi\",\n",
    "    \"yo\",\n",
    "    \"zu\",\n",
    "    \"zh\",\n",
    "]\n",
    "\n",
    "scores = {\"ner\": {}, \"pos\": {}, \"copa\": {}, \"qa\": {}}\n",
    "tasks = scores.keys()\n",
    "f1 = {\"ner\": \"eval_f1\", \"copa\": \"eval_acc\", \"pos\": \"eval_f1_macro\", \"qa\": \"f1\"}\n",
    "inf = math.inf\n",
    "for file in os.listdir(\"../eval_scores/selected\"):\n",
    "    if file.endswith(\".json\"):\n",
    "        try:\n",
    "            with open(os.path.join(\"../eval_scores/selected\", file), \"r\") as f:\n",
    "                data = json.load(f)\n",
    "                task_name = file.split(\".\")[0]\n",
    "\n",
    "                scores[task_name] = data\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error decoding JSON for file: {file}\")\n",
    "        except KeyError:\n",
    "            print(\"KeyError:\", file)\n",
    "\n",
    "# we make a subset consisting of only the languages for which an adapter exists\n",
    "scores_subset = {}\n",
    "no_adapter = {}\n",
    "for task_name in scores:\n",
    "    scores_subset[task_name] = {}\n",
    "    no_adapter[task_name] = {}\n",
    "    for lang_name in scores[task_name]:\n",
    "        if lang_name in existing_adapters:\n",
    "            scores_subset[task_name][lang_name] = scores[task_name][lang_name]\n",
    "        else:\n",
    "            no_adapter[task_name][lang_name] = scores[task_name][lang_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dc0029b938ec292",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:51:00.448594300Z",
     "start_time": "2025-05-23T14:51:00.438370400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_significance(task_name, option1, option2, alternative=\"two-sided\", data=scores):\n",
    "    all_scores1 = []\n",
    "    all_scores2 = []\n",
    "    if task_name == \"all\":\n",
    "        task_names = data.keys()\n",
    "    elif type(task_name) is str:\n",
    "        task_names = [task_name]\n",
    "    else:\n",
    "        task_names = task_name\n",
    "    for task_name in task_names:\n",
    "        for lang_name in data[task_name]:\n",
    "            if option1 in data[task_name][lang_name] and option2 in data[task_name][lang_name]:\n",
    "                score1 = data[task_name][lang_name][option1]\n",
    "                score2 = data[task_name][lang_name][option2]\n",
    "                all_scores1.append(score1)\n",
    "                all_scores2.append(score2)\n",
    "    print(\"average scores\")\n",
    "    print(f\"{option1}: {np.mean(all_scores1)}\")\n",
    "    print(f\"{option2}: {np.mean(all_scores2)}\")\n",
    "    t_stat, p_val = stats.ttest_rel(all_scores1, all_scores2, alternative=alternative)\n",
    "    print(f\"t-statistic: {t_stat}\")\n",
    "    print(f\"p-value: {p_val}\")\n",
    "    return t_stat, p_val\n",
    "\n",
    "\n",
    "def make_boxplot(tasks, columns):\n",
    "    data = []\n",
    "    if tasks == \"all\":\n",
    "        task_names = scores.keys()\n",
    "    elif len(tasks) == 1:\n",
    "        task_names = [tasks]\n",
    "    else:\n",
    "        task_names = tasks\n",
    "    for task in task_names:\n",
    "        for lang_name in scores[task]:\n",
    "            if all(col in scores[task][lang_name] for col in columns):\n",
    "                data.append([task, lang_name] + [scores[task][lang_name][col] for col in columns])\n",
    "    df = pd.DataFrame(data, columns=[\"task\", \"lang_name\"] + columns)\n",
    "    # we divide the scores of qa by 100\n",
    "    df.loc[df[\"task\"] == \"qa\", columns] = df.loc[df[\"task\"] == \"qa\", columns] / 100\n",
    "    # we melt the dataframe to get it in the right format for seaborn\n",
    "    df_melted = df.melt(id_vars=[\"task\", \"lang_name\"], value_vars=columns, var_name=\"method\", value_name=\"score\")\n",
    "    # we plot the data\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x=\"method\", y=\"score\", data=df_melted)\n",
    "    plt.title(f\"Comparison of methods for {tasks}\")\n",
    "    plt.xlabel(\"Method\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f93ac53de87ea1af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:58:23.941609900Z",
     "start_time": "2025-05-23T14:58:23.939614600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL tasks, baseline reconstructed_featural\n",
      "average scores\n",
      "reconstructed_featural_base: 0.5058487615875525\n",
      "reconstructed_featural: 0.5037595015953552\n",
      "t-statistic: 2.9138025357622714\n",
      "p-value: 0.0019575295560539715\n",
      "The difference is statistically significant\n",
      "-----------------------------------\n",
      "ALL tasks, baseline reconstructed_featural_eu\n",
      "average scores\n",
      "reconstructed_featural_base: 0.5042205974641217\n",
      "reconstructed_featural_eu: 0.5035794215130618\n",
      "t-statistic: 1.16891359238375\n",
      "p-value: 0.12180149514837858\n",
      "The difference is not statistically significant\n",
      "-----------------------------------\n",
      "ALL tasks, baseline reconstructed_featural_sr\n",
      "average scores\n",
      "reconstructed_featural_base: 0.5042205974641217\n",
      "reconstructed_featural_sr: 0.5035835770013597\n",
      "t-statistic: 1.1832859546938366\n",
      "p-value: 0.11893574887789471\n",
      "The difference is not statistically significant\n",
      "-----------------------------------\n",
      "sign ['all_reconstructed_featural']\n",
      "\n",
      "notsign ['all_reconstructed_featural_eu', 'all_reconstructed_featural_sr']\n"
     ]
    }
   ],
   "source": [
    "# we will compare \"base\" to \"extended\"\n",
    "extended = \"reconstructed_featural_base\"\n",
    "baselines = [\"reconstructed_featural\", \"reconstructed_featural_eu\", \"reconstructed_featural_sr\"]\n",
    "\n",
    "sign = []\n",
    "not_sign = []\n",
    "for baseline in baselines:\n",
    "    print(f\"ALL tasks, baseline {baseline}\")\n",
    "    t_stat, p_val = get_significance(\"all\", extended, baseline, alternative=\"greater\")\n",
    "    if p_val < 0.05:\n",
    "        print(\"The difference is statistically significant\")\n",
    "        sign.append(\"all\" + \"_\" + baseline)\n",
    "    else:\n",
    "        print(\"The difference is not statistically significant\")\n",
    "        not_sign.append(\"all\" + \"_\" + baseline)\n",
    "    print(\"-----------------------------------\")\n",
    "\n",
    "print(\"sign\", sign)\n",
    "print(\"\\nnotsign\", not_sign)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1821711f4a738c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Result\n",
    "Extending with additional adapters is WORSE than using only the base set!\n",
    "This is coherent with the result that limiting the amount of languages to be taken into account is useful.\n",
    "However, the differences are very small, and the analysis takes all languages across all tasks into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edfb81ef4cbcd465",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:07:11.854581300Z",
     "start_time": "2025-05-23T15:07:11.848033200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL tasks, baseline reconstructed_featural\n",
      "average scores\n",
      "reconstructed_featural_base: 0.5552949616207513\n",
      "reconstructed_featural: 0.5527708276115005\n",
      "t-statistic: 2.116519452597469\n",
      "p-value: 0.018954836285634828\n",
      "The difference is statistically significant\n",
      "-----------------------------------\n",
      "ALL tasks, baseline reconstructed_featural_eu\n",
      "average scores\n",
      "reconstructed_featural_base: 0.5529363382122867\n",
      "reconstructed_featural_eu: 0.5521205430836231\n",
      "t-statistic: 0.9358906262255084\n",
      "p-value: 0.1762735480783661\n",
      "The difference is not statistically significant\n",
      "-----------------------------------\n",
      "ALL tasks, baseline reconstructed_featural_sr\n",
      "average scores\n",
      "reconstructed_featural_base: 0.5529363382122867\n",
      "reconstructed_featural_sr: 0.5521876081608454\n",
      "t-statistic: 0.8901195800448133\n",
      "p-value: 0.18822536738765577\n",
      "The difference is not statistically significant\n",
      "-----------------------------------\n",
      "sign ['all_reconstructed_featural']\n",
      "\n",
      "notsign ['all_reconstructed_featural_eu', 'all_reconstructed_featural_sr']\n"
     ]
    }
   ],
   "source": [
    "# we will compare \"base\" to \"extended\"\n",
    "extended = \"reconstructed_featural_base\"\n",
    "baselines = [\"reconstructed_featural\", \"reconstructed_featural_eu\", \"reconstructed_featural_sr\"]\n",
    "\n",
    "sign = []\n",
    "not_sign = []\n",
    "for baseline in baselines:\n",
    "    print(f\"ALL tasks, baseline {baseline}\")\n",
    "    t_stat, p_val = get_significance(\"all\", extended, baseline, alternative=\"greater\", data=scores_subset)\n",
    "    if p_val < 0.05:\n",
    "        print(\"The difference is statistically significant\")\n",
    "        sign.append(\"all\" + \"_\" + baseline)\n",
    "    else:\n",
    "        print(\"The difference is not statistically significant\")\n",
    "        not_sign.append(\"all\" + \"_\" + baseline)\n",
    "    print(\"-----------------------------------\")\n",
    "\n",
    "print(\"sign\", sign)\n",
    "print(\"\\nnotsign\", not_sign)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea6e7f12ca86a50",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Checking if the closer adapters to sr and eu do benefit from the method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4566a71019b99e3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:07:37.588381100Z",
     "start_time": "2025-05-23T15:07:30.577093100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no glottocodes found for these languages:  []\n",
      "no glottocodes found for these languages:  ['az', 'mg', 'ms', 'or']\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "from qq import LanguageData, TagType\n",
    "from urielplus import urielplus\n",
    "\n",
    "ld = LanguageData.from_db()\n",
    "\n",
    "api = HfApi()\n",
    "# Fetch all AdapterHub xlm-roberta-base adapters\n",
    "models = api.list_models(author=\"AdapterHub\", library=\"adapter-transformers\", search=\"xlm-roberta-base-\")\n",
    "# we print all found models\n",
    "\n",
    "to_load = {\n",
    "    m.modelId: m.modelId.split(\"xlm-roberta-base-\")[-1].rsplit(\"-wiki_pfeiffer\", 1)[0]\n",
    "    for m in models\n",
    "    if m.modelId.startswith(\"AdapterHub/xlm-roberta-base-\") and m.modelId.endswith(\"-wiki_pfeiffer\")\n",
    "}\n",
    "\n",
    "\n",
    "def get_glots(iso_list):\n",
    "    manuals = {\n",
    "        \"Arabic\": \"arab1267\",\n",
    "        \"Swahili\": \"swah1253\",\n",
    "        \"Bengali\": \"beng1282\",\n",
    "        \"Chinese\": \"mand1415\",\n",
    "        \"Persian\": \"west2369\",\n",
    "        \"Yoruba\": \"ilaa1246\",\n",
    "        \"Nepali\": \"nepa1254\",\n",
    "        \"Quechua\": \"cusc1236\",\n",
    "        \"Estonian\": \"esto1258\",\n",
    "        \"Guarani\": \"east2555\",\n",
    "    }\n",
    "\n",
    "    glots = {}\n",
    "    probs = []\n",
    "\n",
    "    for lang in iso_list:\n",
    "        eng = ld.get(lang, tag_type=TagType.BCP_47_CODE).english_name\n",
    "        glot = ld.get(lang, tag_type=TagType.BCP_47_CODE).glottocode\n",
    "        # we need to find if glot is in distances\n",
    "        if not glot:\n",
    "            if eng in manuals.keys():\n",
    "                glot = manuals[eng]\n",
    "        if eng and glot:\n",
    "            glots[eng] = (lang, glot)\n",
    "        else:\n",
    "            probs.append(lang)\n",
    "\n",
    "    print(\"no glottocodes found for these languages: \", probs)\n",
    "\n",
    "    return glots\n",
    "\n",
    "\n",
    "glots = get_glots(to_load.values())\n",
    "iso_list = []\n",
    "iso_s = [scores[key].keys() for key in scores.keys()]\n",
    "\n",
    "\n",
    "# iso_list = [scores[key].keys() for key in scores.keys()]\n",
    "for el in iso_s:\n",
    "    for iso in el:\n",
    "        iso_list.append(iso)\n",
    "eval_glots = get_glots(iso_list)\n",
    "u = urielplus.URIELPlus()\n",
    "\n",
    "\n",
    "def typological_distance(target, glots):\n",
    "    \"\"\"\n",
    "    This function takes a target language and a list of languages.\n",
    "    It weights the other languages depending on their closeness to the target language.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. retrieve closeness score of all languages to target language\n",
    "    weights = {}\n",
    "    probs = []\n",
    "    for lang, codes in glots.items():\n",
    "        iso, glot = codes\n",
    "        # get the distance\n",
    "        try:\n",
    "            dist = u.new_distance(\"featural\", [glot, target])\n",
    "            # print(f\"Distance {lang} to {target}: {dist}\")\n",
    "            weights[iso] = dist\n",
    "\n",
    "        except Exception:\n",
    "            print(f\"Error: {lang} - {glot} - {target}\")\n",
    "            probs.append(lang)\n",
    "    # delete the problematic from glots\n",
    "    for lang in probs:\n",
    "        del glots[lang]\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08902dec135679d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eu_glots = eval_glots.copy()\n",
    "sr_glots = eval_glots.copy()\n",
    "eu_dists = typological_distance(ld.get(\"eu\", TagType.BCP_47_CODE).glottocode, eu_glots)\n",
    "sr_dists = typological_distance(ld.get(\"sr\", TagType.BCP_47_CODE).glottocode, sr_glots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db9465798041ffcb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:08:47.594010700Z",
     "start_time": "2025-05-23T15:08:47.583548300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we add this to the data\n",
    "for task_name in scores_subset:\n",
    "    for lang_name in scores_subset[task_name]:\n",
    "        if lang_name in eu_dists:\n",
    "            scores_subset[task_name][lang_name][\"eu_dist\"] = eu_dists[lang_name]\n",
    "        if lang_name in sr_dists:\n",
    "            scores_subset[task_name][lang_name][\"sr_dist\"] = sr_dists[lang_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fde88a969d6c1173",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:10:37.947123600Z",
     "start_time": "2025-05-23T15:10:37.943349200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median distance eu 0.5867\n",
      "median distance sr 0.4646\n"
     ]
    }
   ],
   "source": [
    "# we run the significance test again, but only taking into account the closest languages\n",
    "median_dist_eu = np.median(list(eu_dists.values()))\n",
    "median_dist_sr = np.median(list(sr_dists.values()))\n",
    "print(\"median distance eu\", median_dist_eu)\n",
    "print(\"median distance sr\", median_dist_sr)\n",
    "subset_eu = {}\n",
    "for task_name in scores_subset:\n",
    "    subset_eu[task_name] = {}\n",
    "    for lang_name in scores_subset[task_name]:\n",
    "        if lang_name in eu_dists and eu_dists[lang_name] < median_dist_eu:\n",
    "            subset_eu[task_name][lang_name] = scores_subset[task_name][lang_name]\n",
    "subset_sr = {}\n",
    "for task_name in scores_subset:\n",
    "    subset_sr[task_name] = {}\n",
    "    for lang_name in scores_subset[task_name]:\n",
    "        if lang_name in sr_dists and sr_dists[lang_name] < median_dist_sr:\n",
    "            subset_sr[task_name][lang_name] = scores_subset[task_name][lang_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a243abb5643f92b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:11:38.224063600Z",
     "start_time": "2025-05-23T15:11:38.216160400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL tasks, baseline reconstructed_featural_base\n",
      "average scores\n",
      "reconstructed_featural_eu: 0.6159393202082123\n",
      "reconstructed_featural_base: 0.6164917575087449\n",
      "t-statistic: -0.7808833941300625\n",
      "p-value: 0.7796950256740595\n",
      "The difference is not statistically significant\n",
      "-----------------------------------\n",
      "ALL tasks, baseline reconstructed_featural_sr\n",
      "average scores\n",
      "reconstructed_featural_eu: 0.6159393202082123\n",
      "reconstructed_featural_sr: 0.615646222253811\n",
      "t-statistic: 0.5068908152872996\n",
      "p-value: 0.30785337274677144\n",
      "The difference is not statistically significant\n",
      "-----------------------------------\n",
      "sign []\n",
      "\n",
      "notsign ['all_reconstructed_featural_base', 'all_reconstructed_featural_sr']\n"
     ]
    }
   ],
   "source": [
    "# we run significance tests\n",
    "# we will compare \"base\" to \"extended\"\n",
    "base = \"reconstructed_featural_eu\"\n",
    "baselines = [\"reconstructed_featural_base\", \"reconstructed_featural_sr\"]\n",
    "\n",
    "sign = []\n",
    "not_sign = []\n",
    "for baseline in baselines:\n",
    "    print(f\"ALL tasks, baseline {baseline}\")\n",
    "    t_stat, p_val = get_significance(\"all\", base, baseline, alternative=\"greater\", data=subset_eu)\n",
    "    if p_val < 0.05:\n",
    "        print(\"The difference is statistically significant\")\n",
    "        sign.append(\"all\" + \"_\" + baseline)\n",
    "    else:\n",
    "        print(\"The difference is not statistically significant\")\n",
    "        not_sign.append(\"all\" + \"_\" + baseline)\n",
    "    print(\"-----------------------------------\")\n",
    "\n",
    "print(\"sign\", sign)\n",
    "print(\"\\nnotsign\", not_sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4dc587fbd5b67762",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:17:19.331549700Z",
     "start_time": "2025-05-23T15:17:19.323234300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'ner': {'ace': -0.011021847245055227,\n  'af': 0.001175962574009648,\n  'als': -0.004561523548865409,\n  'am': 0.001425601425601497,\n  'an': 0.005389832248066773,\n  'arz': 0.022140221402214,\n  'ar': -0.0011907621544379743,\n  'as': 0.025723121702746987,\n  'ay': -0.005677924620655861,\n  'bar': 0.015622647191687933,\n  'ba': -0.008732237834405049,\n  'be': -0.0016130765290583993,\n  'bg': -0.002204374925134922,\n  'bn': -0.0024011779702780567,\n  'bo': 0.0,\n  'br': -0.007233019619595993,\n  'bs': -0.0035284389977650044,\n  'ca': -0.0038713937401643195,\n  'cdo': -0.004014272970562005,\n  'ceb': -0.014160068092130773,\n  'ce': 0.0011741859729937631,\n  'ckb': 0.0001462273347631049,\n  'co': -0.008230452674897193,\n  'crh': 0.010921940250562201,\n  'cs': 0.0009501219578313957,\n  'cv': -0.0018302447952412981,\n  'cy': -0.007468860525911114,\n  'da': -0.0008571672699058119,\n  'de': -0.0009523809523810378,\n  'diq': 0.0,\n  'dv': 0.0,\n  'el': -0.0015832153311616803,\n  'en': -0.00012661675768255165,\n  'eo': -0.0012893444691355338,\n  'es': -0.0014692788515897615,\n  'et': -0.0021159642805562706,\n  'eu': -0.012945043523727162,\n  'ext': 0.0012426597792452032,\n  'fi': -0.002860244278155122,\n  'fo': -0.013967896367220733,\n  'frr': 0.009589566551591822,\n  'fr': -0.001710088043517799,\n  'fur': -0.009157266091572636,\n  'fy': -0.0055223718528413235,\n  'gan': -0.000848382014301291,\n  'ga': 0.002113822203156146,\n  'gd': -0.003642456472645106,\n  'gl': -0.0017521239783946374,\n  'gn': 0.011824278826729873,\n  'gu': 0.0021728861596598814,\n  'hak': -0.0012890750886239144,\n  'he': -0.0027966581624104814,\n  'hi': -0.0015615337043909383,\n  'hr': -0.00043425661337048727,\n  'hu': -0.0020156114102012346,\n  'hy': -0.007698757429525194,\n  'id': 0.0018577068139368214,\n  'ig': 0.012071184484977626,\n  'ilo': -0.020256540513081123,\n  'is': 0.0022291750644629627,\n  'it': -0.0035732058949977663,\n  'ja': -0.001004151195635572,\n  'jv': -0.003418988956123137,\n  'ka': -0.006427339270478116,\n  'kk': -0.002355818258712783,\n  'km': 7.153075822607935e-05,\n  'kn': -0.0017670393076090751,\n  'ko': -0.0019531336960627033,\n  'ku': 0.029540836364257195,\n  'ky': -0.0015389762462361678,\n  'lb': -0.0031091241251079427,\n  'lmo': 0.0048661800486617945,\n  'ln': 0.006561740718386722,\n  'lt': -0.001085936067387494,\n  'lv': -0.001906476986109129,\n  'mhr': -0.00029626703535456933,\n  'min': -0.004377104377104313,\n  'mi': 0.00030915202410264353,\n  'mk': 0.0003918185038778166,\n  'ml': -0.00377915541179652,\n  'mn': -0.027401129943502855,\n  'mr': -0.0038570194202524055,\n  'mt': 0.01066053511705678,\n  'my': -0.009542732789965258,\n  'mzn': -0.003489955737146777,\n  'nap': -0.005493786788750676,\n  'nds': -0.004601467980516527,\n  'ne': 0.015810276679841917,\n  'nl': -0.0008644578477577936,\n  'no': -0.0006252852554405885,\n  'oc': 0.00259587020648977,\n  'os': -0.0012121212121212754,\n  'pa': -0.009564385705590761,\n  'pl': -0.0018181353809429979,\n  'pnb': 0.008733624454148436,\n  'ps': 0.0049612522354479105,\n  'pt': -0.0010321058645730297,\n  'qu': 0.0022746999491186637,\n  'rm': -0.00783659436776385,\n  'ro': -0.0020065781069520394,\n  'ru': -0.0006517700214587752,\n  'rw': -0.010520163646990044,\n  'sah': 0.03072895135731013,\n  'scn': -0.001646598744468486,\n  'sco': 0.0,\n  'sd': 0.007235722369253517,\n  'sh': 0.003500792284492904,\n  'si': -0.00528711015928246,\n  'sl': -0.0006816336087902553,\n  'so': 0.018475064603320712,\n  'sq': -0.004986026861741322,\n  'sr': -0.0025278590699111536,\n  'su': 0.0,\n  'sv': 3.8653609589101023e-05,\n  'sw': -0.0015967168466607395,\n  'ta': -0.007479431347017396,\n  'te': -0.0039835388021585705,\n  'tg': 0.0031958379784466917,\n  'th': 0.0002371397719316548,\n  'tk': -0.011892849995711774,\n  'tl': -0.005259018818769334,\n  'tr': -0.0004200499532810431,\n  'tt': -0.012089964903121642,\n  'ug': -0.001374255611543751,\n  'uk': 0.0017553091784232588,\n  'ur': -0.0055271064633633515,\n  'uz': -0.0026885541409711333,\n  'vep': 0.0005719187875321552,\n  'vi': -0.0035523699862110014,\n  'vls': -0.0280930142521838,\n  'war': -0.039820904334705476,\n  'wuu': -0.0033713139589467978,\n  'xmf': -0.010216623137194736,\n  'yo': -0.04074374123179664,\n  'zea': 0.0047959795405554395,\n  'zh': -0.0020533716105338995},\n 'pos': {'af': 4.297367292127596e-05,\n  'am': -0.0006767553944381222,\n  'apu': -0.0008652889543742937,\n  'aqz': 0.00013764013764012983,\n  'ar': -0.000506547520257361,\n  'be': 0.0004088219465695486,\n  'bg': -0.0010337785270828626,\n  'bho': 0.00011439706081234347,\n  'bm': -7.03047577972904e-05,\n  'br': 0.0022566835025390475,\n  'bxr': 0.0021108442244666126,\n  'ca': 0.0001969093855594961,\n  'ckt': -0.0003318391754684735,\n  'cop': -0.0013868357891055894,\n  'cs': -0.00012912032284606578,\n  'cy': 0.0015053735119061606,\n  'da': 0.00026521422189396127,\n  'de': -0.00026661660610871607,\n  'el': 0.0008827775546821348,\n  'en': -8.338497521320765e-05,\n  'es': 0.0003510044452671446,\n  'et': 0.039321340863233356,\n  'eu': 0.006376923718852512,\n  'fi': -0.0007412789948711973,\n  'fo': 0.00107039257490249,\n  'fr': 0.00016219305327347389,\n  'ga': -0.002302207589698013,\n  'gd': 0.0009543704737058345,\n  'gl': 0.0008265874131009321,\n  'gsw': 0.004157628524257551,\n  'gun': 0.0003078313187835219,\n  'gv': -0.0035866677278985626,\n  'he': -0.0002887757492672227,\n  'hi': -0.00031917717542484514,\n  'hr': 0.0005779104331264939,\n  'hu': 0.041604498656944155,\n  'hy': 0.0015447934237943217,\n  'id': -0.000507138476934732,\n  'is': 0.0003313922425737248,\n  'it': 6.740063738941426e-05,\n  'ja': -0.0026565607136713187,\n  'kk': -0.001313241391965203,\n  'kmr': 0.008112160646865374,\n  'koi': -0.0004157302394625084,\n  'ko': -5.3312031843111285e-05,\n  'kpv': -0.0005967902744405951,\n  'lt': 0.001949145399060992,\n  'lv': 0.00149129024057304,\n  'mdf': -0.00027144242620325,\n  'mr': 0.0,\n  'mt': -0.0016695260065706652,\n  'myu': -0.00021462153254064864,\n  'myv': 0.0022946545289329046,\n  'nl': 0.0004629956977839633,\n  'no': 8.712538799071634e-05,\n  'olo': -0.01989618111777658,\n  'pcm': 0.0007629070061863641,\n  'pl': 0.0006539878796302245,\n  'pt': -0.00015610720017578128,\n  'ro': 0.0006687827180535955,\n  'ru': 0.0009091704861370342,\n  'sl': 0.00028351945066751316,\n  'sms': -0.0021551114889581946,\n  'sq': 0.0016007799541780665,\n  'sr': 0.0004880726468592389,\n  'sv': 6.757765938980587e-05,\n  'ta': -0.0003320659998475861,\n  'te': -0.0005826772700639471,\n  'th': -0.0004835875894899089,\n  'tl': 0.0023374851807958508,\n  'tpn': 0.0,\n  'tr': 0.004058330174734892,\n  'ug': 0.0019179900505350567,\n  'uk': -0.00019706738392710754,\n  'ur': -6.069481812837063e-05,\n  'vi': -5.9406062377975744e-05,\n  'wbp': 0.0036658985648595765,\n  'wo': -0.0004490252399350636,\n  'yo': 5.699793616439908e-05,\n  'yue': -0.001498878930350167,\n  'zh': -0.001886517601851323},\n 'copa': {'et': 0.0,\n  'ht': 0.0020000000000000018,\n  'id': -0.0040000000000000036,\n  'it': 0.0040000000000000036,\n  'qu': -0.006000000000000005,\n  'sw': -0.010000000000000009,\n  'ta': 0.0020000000000000018,\n  'th': -0.006000000000000005,\n  'tr': -0.005999999999999894,\n  'vi': -0.0020000000000000018,\n  'zh': 0.0040000000000000036},\n 'qa': {'ar': -0.0036256040877888918,\n  'de': 0.0007689195185165421,\n  'el': 0.0013811406915709146,\n  'en': -0.0011140407580034761,\n  'es': 0.0013110342176085865,\n  'hi': -0.0006930402404931035,\n  'ro': -0.0034753380986455307,\n  'ru': 0.004760132374501236,\n  'th': 0.01462051487261562,\n  'tr': 0.00626545582766036,\n  'vi': 0.0013046131594177668,\n  'zh': -0.020876145329926765}}"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference_eu_base = {}\n",
    "for task_name in scores:\n",
    "    difference_eu_base[task_name] = {}\n",
    "    for lang_name in scores[task_name]:\n",
    "        if (\n",
    "            \"reconstructed_featural_base\" in scores[task_name][lang_name]\n",
    "            and \"reconstructed_featural_eu\" in scores[task_name][lang_name]\n",
    "        ):\n",
    "            difference_eu_base[task_name][lang_name] = (\n",
    "                scores[task_name][lang_name][\"reconstructed_featural_eu\"]\n",
    "                - scores[task_name][lang_name][\"reconstructed_featural_base\"]\n",
    "            )\n",
    "difference_eu_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dceb90f89b749b56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:17:49.967230400Z",
     "start_time": "2025-05-23T15:17:49.961967700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[('pos', 'hu', 0.041604498656944155),\n ('pos', 'et', 0.039321340863233356),\n ('ner', 'sah', 0.03072895135731013),\n ('ner', 'ku', 0.029540836364257195),\n ('ner', 'as', 0.025723121702746987),\n ('ner', 'arz', 0.022140221402214),\n ('ner', 'so', 0.018475064603320712),\n ('ner', 'ne', 0.015810276679841917),\n ('ner', 'bar', 0.015622647191687933),\n ('qa', 'th', 0.01462051487261562)]"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we check which languages are the most different\n",
    "diffs = []\n",
    "for task_name in difference_eu_base:\n",
    "    for lang_name in difference_eu_base[task_name]:\n",
    "        diffs.append((task_name, lang_name, difference_eu_base[task_name][lang_name]))\n",
    "diffs = sorted(diffs, key=lambda x: x[2], reverse=True)\n",
    "diffs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd8b5eec9e770783",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:18:25.988153800Z",
     "start_time": "2025-05-23T15:18:25.963336700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[('ner', 'yo', -0.04074374123179664),\n ('ner', 'war', -0.039820904334705476),\n ('ner', 'vls', -0.0280930142521838),\n ('ner', 'mn', -0.027401129943502855),\n ('qa', 'zh', -0.020876145329926765),\n ('ner', 'ilo', -0.020256540513081123),\n ('pos', 'olo', -0.01989618111777658),\n ('ner', 'ceb', -0.014160068092130773),\n ('ner', 'fo', -0.013967896367220733),\n ('ner', 'eu', -0.012945043523727162)]"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we check which languages are the most different\n",
    "diffs = []\n",
    "for task_name in difference_eu_base:\n",
    "    for lang_name in difference_eu_base[task_name]:\n",
    "        diffs.append((task_name, lang_name, difference_eu_base[task_name][lang_name]))\n",
    "diffs = sorted(diffs, key=lambda x: x[2], reverse=False)\n",
    "diffs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72128326f42ac54b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Unexpected result\n",
    "Adding more adapters does not seem to be beneficial.\n",
    "We see an overall decrease in score, even though the difference is very small.\n",
    "Surprisingly, basque itself is one of the languages that suffers the GREATEST decrease in performance when the Basque adapter is taken into account!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f0a6ec57c74247",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
