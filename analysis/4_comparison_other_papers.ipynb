{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T13:46:26.762570700Z",
     "start_time": "2025-05-26T13:46:19.993057Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# we look at path \"./eval_scores\", in which there are json files with scores\n",
    "import os\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from qq import LanguageData\n",
    "import math\n",
    "\n",
    "ld = LanguageData.from_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "423c17a8be3e4f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T13:50:41.636969900Z",
     "start_time": "2025-05-26T13:50:41.610166300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = {\"ner\": {}, \"pos\": {}, \"copa\": {}, \"qa\": {}}\n",
    "f1 = {\"ner\": \"eval_f1\", \"copa\": \"eval_acc\", \"pos\": \"eval_f1_macro\", \"qa\": \"f1\"}\n",
    "inf = math.inf\n",
    "\n",
    "\n",
    "def best_scores(scores):\n",
    "    best_scores = {}\n",
    "    for lang, types in scores.items():\n",
    "        highest = (-inf, \"None\")\n",
    "        for type, value in types.items():\n",
    "            if isinstance(value, float):\n",
    "                if value > highest[0]:\n",
    "                    highest = (value, type)\n",
    "            else:\n",
    "                for reconstructed, score in value.items():\n",
    "                    if score > highest[0]:\n",
    "                        highest = (score, reconstructed)\n",
    "\n",
    "        # print(lang, highest)\n",
    "        best_scores[lang] = highest\n",
    "    pprint(best_scores)\n",
    "    # we count how many time each type was the best\n",
    "    best_types = {}\n",
    "    for lang, (score, type) in best_scores.items():\n",
    "        if type not in best_types.keys():\n",
    "            best_types[type] = 0\n",
    "        best_types[type] += 1\n",
    "    pprint(best_types)\n",
    "\n",
    "\n",
    "for file in os.listdir(\"../eval_scores/selected\"):\n",
    "    if file.endswith(\".json\"):\n",
    "        try:\n",
    "            with open(os.path.join(\"../eval_scores/selected\", file), \"r\") as f:\n",
    "                data = json.load(f)\n",
    "                task_name = file.split(\".\")[0]\n",
    "\n",
    "                scores[task_name] = data\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error decoding JSON for file: {file}\")\n",
    "        except KeyError:\n",
    "            print(\"KeyError:\", file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1539d877b2e176",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Comparison with other papers\n",
    "\n",
    "## EMEA\n",
    "EMEA check NER and POS on quite a few languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74633eddf25af434",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T13:46:26.839324400Z",
     "start_time": "2025-05-26T13:46:26.792027600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mr {'baseline_en': 0.37207165824529165, 'Best': (0.5046728971962616, 'reconstructed_morphological_threshold')}\n",
      "bn {'baseline_en': 0.3659942363112392, 'Best': (0.5985275010827199, 'reconstructed_syntactic_threshold')}\n",
      "ta {'baseline_en': 0.33454252317613864, 'Best': (0.4292682926829268, 'reconstructed_featural_limit')}\n",
      "fo {'baseline_en': -inf, 'Best': (0.587360594795539, 'reconstructed_morphological_limit')}\n",
      "no {'baseline_en': 0.7269464204137571, 'Best': (0.7522368421052632, 'reconstructed_syntactic_threshold')}\n",
      "da {'baseline_en': 0.784997910572503, 'Best': (0.7937480419117904, 'reconstructed_featural_threshold')}\n",
      "be {'baseline_en': 0.5907769007062734, 'Best': (0.7273440564927423, 'reconstructed_featural_limit')}\n",
      "uk {'baseline_en': 0.5676052810476224, 'Best': (0.6025231397608616, 'reconstructed_featural')}\n",
      "bg {'baseline_en': 0.6946546253356114, 'Best': (0.7437472722999966, 'reconstructed_featural_base')}\n"
     ]
    }
   ],
   "source": [
    "# we print the highest 3 key-value pairs in a combination\n",
    "def get_highest(task, language):\n",
    "    result = {\"baseline_en\": -inf, \"Best\": (-inf, None)}\n",
    "    for type, value in scores[task][language].items():\n",
    "        # value = value*100\n",
    "        # we get the baseline of english\n",
    "        if type == \"baseline_en\":\n",
    "            result[\"baseline_en\"] = value\n",
    "        if \"baseline\" not in type:\n",
    "            if value > result[\"Best\"][0]:\n",
    "                result[\"Best\"] = (value, type)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "task = \"ner\"\n",
    "to_check = [\"mr\", \"bn\", \"ta\", \"fo\", \"no\", \"da\", \"be\", \"uk\", \"bg\"]\n",
    "\n",
    "for lang in to_check:\n",
    "    if lang in scores[task].keys():\n",
    "        print(lang, get_highest(task, lang))\n",
    "    else:\n",
    "        print(f\"{lang} not in scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d299af4635ee6de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T13:46:26.840452900Z",
     "start_time": "2025-05-26T13:46:26.811433300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "task2lang = {\n",
    "    \"ner\": [\"mr\", \"bn\", \"ta\", \"fo\", \"no\", \"da\", \"be\", \"uk\", \"bg\"],\n",
    "    \"pos\": [\"mr\", \"bho\", \"ta\", \"fo\", \"no\", \"da\", \"be\", \"uk\", \"bg\"],\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize a dictionary to store results\n",
    "data = {\"baseline_en\": [], \"Best\": []}\n",
    "\n",
    "# Populate the dictionary with values for each language\n",
    "task = \"pos\"\n",
    "for lang in task2lang[task]:\n",
    "    if lang in scores[task].keys():\n",
    "        result = get_highest(task, lang)\n",
    "        data[\"baseline_en\"].append(result[\"baseline_en\"])\n",
    "        data[\"Best\"].append(result[\"Best\"][0])  # Append only the score from the tuple\n",
    "    else:\n",
    "        data[\"baseline_en\"].append(None)\n",
    "        data[\"Best\"].append(None)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame.from_dict(data, orient=\"index\", columns=to_check)\n",
    "# we add a row \"relative improvement\" which is the difference between the best and the baseline\n",
    "df.loc[\"relative improvement\"] = 1 - df.loc[\"baseline_en\"] / df.loc[\"Best\"]\n",
    "df.loc[\"absolute improvement\"] = df.loc[\"Best\"] - df.loc[\"baseline_en\"]\n",
    "# we multiply all by 100\n",
    "df = df * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf5d76d5e877345",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Scores for EMEA:\n",
    "Method mr bn ta avg. fo no da avg. be uk bg avg. avg.\n",
    "En 48.0 54.4 29.6 44.0 57.5 73.3 80.5 70.4 67.1 67.6 71.1 68.6 61.0\n",
    "EMEA-s10 57.5 63.2 38.3 53.0 61.6 74.9 82.0 72.8 72.9 72.9 75.1 73.6 66.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d363d219b39c2804",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T13:46:26.927095100Z",
     "start_time": "2025-05-26T13:46:26.825949100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mr</th>\n      <th>bn</th>\n      <th>ta</th>\n      <th>fo</th>\n      <th>no</th>\n      <th>da</th>\n      <th>be</th>\n      <th>uk</th>\n      <th>bg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>baseline_en</th>\n      <td>48.000000</td>\n      <td>54.400000</td>\n      <td>29.600000</td>\n      <td>57.500000</td>\n      <td>73.300000</td>\n      <td>80.500000</td>\n      <td>67.100000</td>\n      <td>67.600000</td>\n      <td>71.100000</td>\n    </tr>\n    <tr>\n      <th>EMEA-s10</th>\n      <td>57.500000</td>\n      <td>63.200000</td>\n      <td>38.300000</td>\n      <td>61.600000</td>\n      <td>74.900000</td>\n      <td>82.000000</td>\n      <td>72.900000</td>\n      <td>72.900000</td>\n      <td>75.100000</td>\n    </tr>\n    <tr>\n      <th>relative improvement</th>\n      <td>0.165217</td>\n      <td>0.139241</td>\n      <td>0.227154</td>\n      <td>0.066558</td>\n      <td>0.021362</td>\n      <td>0.018293</td>\n      <td>0.079561</td>\n      <td>0.072702</td>\n      <td>0.053262</td>\n    </tr>\n    <tr>\n      <th>absolute improvement</th>\n      <td>9.500000</td>\n      <td>8.800000</td>\n      <td>8.700000</td>\n      <td>4.100000</td>\n      <td>1.600000</td>\n      <td>1.500000</td>\n      <td>5.800000</td>\n      <td>5.300000</td>\n      <td>4.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                             mr         bn         ta         fo         no  \\\nbaseline_en           48.000000  54.400000  29.600000  57.500000  73.300000   \nEMEA-s10              57.500000  63.200000  38.300000  61.600000  74.900000   \nrelative improvement   0.165217   0.139241   0.227154   0.066558   0.021362   \nabsolute improvement   9.500000   8.800000   8.700000   4.100000   1.600000   \n\n                             da         be         uk         bg  \nbaseline_en           80.500000  67.100000  67.600000  71.100000  \nEMEA-s10              82.000000  72.900000  72.900000  75.100000  \nrelative improvement   0.018293   0.079561   0.072702   0.053262  \nabsolute improvement   1.500000   5.800000   5.300000   4.000000  "
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we make a dataframe with EMEA scores\n",
    "emea = {\n",
    "    \"baseline_en\": [\n",
    "        48.0,\n",
    "        54.4,\n",
    "        29.6,\n",
    "        57.5,\n",
    "        73.3,\n",
    "        80.5,\n",
    "        67.1,\n",
    "        67.6,\n",
    "        71.1,\n",
    "    ],\n",
    "    \"EMEA-s10\": [57.5, 63.2, 38.3, 61.6, 74.9, 82.0, 72.9, 72.9, 75.1],\n",
    "}\n",
    "emea_df = pd.DataFrame.from_dict(emea, orient=\"index\", columns=to_check)\n",
    "# we have to divide by 100\n",
    "emea_df.loc[\"relative improvement\"] = 1 - emea_df.loc[\"baseline_en\"] / emea_df.loc[\"EMEA-s10\"]\n",
    "emea_df.loc[\"absolute improvement\"] = emea_df.loc[\"EMEA-s10\"] - emea_df.loc[\"baseline_en\"]\n",
    "emea_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fe2977ba10f103f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T13:46:26.947580300Z",
     "start_time": "2025-05-26T13:46:26.871517Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mr</th>\n      <th>bn</th>\n      <th>ta</th>\n      <th>fo</th>\n      <th>no</th>\n      <th>da</th>\n      <th>be</th>\n      <th>uk</th>\n      <th>bg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>emea_baseline_en</th>\n      <td>48.000000</td>\n      <td>54.400000</td>\n      <td>29.600000</td>\n      <td>57.500000</td>\n      <td>73.300000</td>\n      <td>80.500000</td>\n      <td>67.100000</td>\n      <td>67.600000</td>\n      <td>71.100000</td>\n    </tr>\n    <tr>\n      <th>EMEA-s10</th>\n      <td>57.500000</td>\n      <td>63.200000</td>\n      <td>38.300000</td>\n      <td>61.600000</td>\n      <td>74.900000</td>\n      <td>82.000000</td>\n      <td>72.900000</td>\n      <td>72.900000</td>\n      <td>75.100000</td>\n    </tr>\n    <tr>\n      <th>our_baseline_en</th>\n      <td>42.489162</td>\n      <td>33.508854</td>\n      <td>39.149474</td>\n      <td>54.998776</td>\n      <td>63.696679</td>\n      <td>77.977372</td>\n      <td>66.259707</td>\n      <td>61.913028</td>\n      <td>63.136868</td>\n    </tr>\n    <tr>\n      <th>Approximation_method</th>\n      <td>43.336831</td>\n      <td>33.885334</td>\n      <td>40.074814</td>\n      <td>57.738947</td>\n      <td>64.388078</td>\n      <td>82.669088</td>\n      <td>67.447689</td>\n      <td>62.776158</td>\n      <td>63.356007</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                             mr         bn         ta         fo         no  \\\nemea_baseline_en      48.000000  54.400000  29.600000  57.500000  73.300000   \nEMEA-s10              57.500000  63.200000  38.300000  61.600000  74.900000   \nour_baseline_en       42.489162  33.508854  39.149474  54.998776  63.696679   \nApproximation_method  43.336831  33.885334  40.074814  57.738947  64.388078   \n\n                             da         be         uk         bg  \nemea_baseline_en      80.500000  67.100000  67.600000  71.100000  \nEMEA-s10              82.000000  72.900000  72.900000  75.100000  \nour_baseline_en       77.977372  66.259707  61.913028  63.136868  \nApproximation_method  82.669088  67.447689  62.776158  63.356007  "
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we rename baseline_en index in df to \"our_baseline_en\"\n",
    "df.rename(index={\"baseline_en\": \"our_baseline_en\"}, inplace=True)\n",
    "df.rename(index={\"Best\": \"Approximation_method\"}, inplace=True)\n",
    "\n",
    "# we rename the baseline_en index in emea_df to \"emea_baseline_en\"\n",
    "emea_df.rename(index={\"baseline_en\": \"emea_baseline_en\"}, inplace=True)\n",
    "# we only take the first two columns\n",
    "emea_df = emea_df.iloc[:2, :]\n",
    "df = df.iloc[:2, :]\n",
    "# we concatenate the two dataframes\n",
    "merged_df = pd.concat([emea_df, df])\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689cdd59cd6fe84b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# No train but gain\n",
    "ner:\n",
    "ar bg de el es fr hi ru sw tr ur vi zh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbd325c2d7138cb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T13:46:26.948896200Z",
     "start_time": "2025-05-26T13:46:26.892444200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ar {'baseline_en': 0.2433960213066638, 'Best': (0.3701895128473433, 'reconstructed_morphological_limit')}\n",
      "bg {'baseline_en': 0.6946546253356114, 'Best': (0.7437472722999966, 'reconstructed_featural_base')}\n",
      "de {'baseline_en': 0.7022521008403362, 'Best': (0.7159136884693189, 'reconstructed_syntactic_threshold')}\n",
      "el {'baseline_en': 0.6577599815192701, 'Best': (0.72478919455149, 'reconstructed_morphological_limit')}\n",
      "es {'baseline_en': 0.7115317751593586, 'Best': (0.7245094267025779, 'no_train_gain')}\n",
      "fr {'baseline_en': 0.7141884385191557, 'Best': (0.7355297017143272, 'reconstructed_syntactic_limit')}\n",
      "hi {'baseline_en': 0.5677308024158757, 'Best': (0.6572411157814291, 'reconstructed_morphological_threshold')}\n",
      "ru {'baseline_en': 0.5094573519414565, 'Best': (0.634243480258875, 'reconstructed_morphological_limit')}\n",
      "sw {'baseline_en': 0.6110886280857952, 'Best': (0.6800986842105263, 'reconstructed_morphological_threshold')}\n",
      "tr {'baseline_en': 0.5816221413364467, 'Best': (0.6042429686960127, 'reconstructed_syntactic_limit')}\n",
      "ur {'baseline_en': 0.23623853211009174, 'Best': (0.426128890837352, 'reconstructed_featural_threshold')}\n",
      "vi {'baseline_en': 0.6122260475270803, 'Best': (0.6648842087943729, 'reconstructed_syntactic_limit')}\n",
      "zh {'baseline_en': 0.1625176803394625, 'Best': (0.20129850336818364, 'reconstructed_featural_limit')}\n"
     ]
    }
   ],
   "source": [
    "# we look at the languages from no train but gain paper\n",
    "to_test = [\"ar\", \"bg\", \"de\", \"el\", \"es\", \"fr\", \"hi\", \"ru\", \"sw\", \"tr\", \"ur\", \"vi\", \"zh\"]\n",
    "# we get the scores for these languages\n",
    "for lang in to_test:\n",
    "    if lang in scores[\"ner\"].keys():\n",
    "        print(lang, get_highest(\"ner\", lang))\n",
    "    else:\n",
    "        print(f\"{lang} not in scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e8d46617bced6e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# QXUAD\n",
    "F1 scores:\n",
    "Model \ten \tar \tde \tel \tes \thi \tru \tth \ttr \tvi \tzh \tro \tavg\n",
    "mBERT \t83.5 \t61.5 \t70.6 \t62.6 \t75.5 \t59.2 \t71.3 \t42.7 \t55.4 \t69.5 \t58.0 \t72.7 \t65.2\n",
    "XLM-R Large \t86.5 \t68.6 \t80.4 \t79.8 \t82.0 \t76.7 \t80.1 \t74.2 \t75.9 \t79.1 \t59.3 \t83.6 \t77.2\n",
    "Translate-train mBERT \t83.5 \t68.0 \t75.6 \t70.0 \t80.2 \t69.6 \t75.0 \t36.9 \t68.9 \t75.6 \t66.2 \t- \t70.0\n",
    "Translate-test BERT-L \t87.9 \t73.7 \t79.8 \t79.4 \t82.0 \t74.9 \t79.9 \t64.6 \t67.4 \t76.3 \t73.7 \t- \t76.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ea43c40a2b83e050",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T15:02:59.238220600Z",
     "start_time": "2025-05-26T15:02:59.228100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>en</th>\n      <th>ar</th>\n      <th>de</th>\n      <th>el</th>\n      <th>es</th>\n      <th>hi</th>\n      <th>ru</th>\n      <th>th</th>\n      <th>tr</th>\n      <th>vi</th>\n      <th>zh</th>\n      <th>ro</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>mBERT</th>\n      <td>83.5</td>\n      <td>61.5</td>\n      <td>70.6</td>\n      <td>62.6</td>\n      <td>75.5</td>\n      <td>59.2</td>\n      <td>71.3</td>\n      <td>42.7</td>\n      <td>55.4</td>\n      <td>69.5</td>\n      <td>58.0</td>\n      <td>72.7</td>\n    </tr>\n    <tr>\n      <th>XLM-R Large</th>\n      <td>86.5</td>\n      <td>68.6</td>\n      <td>80.4</td>\n      <td>79.8</td>\n      <td>82.0</td>\n      <td>76.7</td>\n      <td>80.1</td>\n      <td>74.2</td>\n      <td>75.9</td>\n      <td>79.1</td>\n      <td>59.3</td>\n      <td>83.6</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "               en    ar    de    el    es    hi    ru    th    tr    vi    zh  \\\nmBERT        83.5  61.5  70.6  62.6  75.5  59.2  71.3  42.7  55.4  69.5  58.0   \nXLM-R Large  86.5  68.6  80.4  79.8  82.0  76.7  80.1  74.2  75.9  79.1  59.3   \n\n               ro  \nmBERT        72.7  \nXLM-R Large  83.6  "
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we make a dataframe out of this\n",
    "to_test = [\"en\", \"ar\", \"de\", \"el\", \"es\", \"hi\", \"ru\", \"th\", \"tr\", \"vi\", \"zh\", \"ro\"]\n",
    "qx = {\n",
    "    \"mBERT\": [83.5, 61.5, 70.6, 62.6, 75.5, 59.2, 71.3, 42.7, 55.4, 69.5, 58.0, 72.7],\n",
    "    \"XLM-R Large\": [86.5, 68.6, 80.4, 79.8, 82.0, 76.7, 80.1, 74.2, 75.9, 79.1, 59.3, 83.6],\n",
    "    # \"Translate-train mBERT\": [83.5, 68.0, 75.6, 70.0, 80.2, 69.6, 75.0, 36.9, 68.9, 75.6],\n",
    "    # \"Translate-test BERT-L\": [87.9, 73.7, 79.8, 79.4, 82.0, 74.9, 79.9, 64.6, 67.4, 76.3, 73.7],\n",
    "}\n",
    "qx_df = pd.DataFrame.from_dict(qx, orient=\"index\", columns=to_test)\n",
    "qx_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6ae5011773ad6571",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T15:02:59.406193100Z",
     "start_time": "2025-05-26T15:02:59.401178100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>en</th>\n      <th>ar</th>\n      <th>de</th>\n      <th>el</th>\n      <th>es</th>\n      <th>hi</th>\n      <th>ru</th>\n      <th>th</th>\n      <th>tr</th>\n      <th>vi</th>\n      <th>zh</th>\n      <th>ro</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>mBERT</th>\n      <td>83.5</td>\n      <td>61.5</td>\n      <td>70.6</td>\n      <td>62.6</td>\n      <td>75.5</td>\n      <td>59.2</td>\n      <td>71.3</td>\n      <td>42.7</td>\n      <td>55.4</td>\n      <td>69.5</td>\n      <td>58.0</td>\n      <td>72.7</td>\n    </tr>\n    <tr>\n      <th>XLM-R Large</th>\n      <td>86.5</td>\n      <td>68.6</td>\n      <td>80.4</td>\n      <td>79.8</td>\n      <td>82.0</td>\n      <td>76.7</td>\n      <td>80.1</td>\n      <td>74.2</td>\n      <td>75.9</td>\n      <td>79.1</td>\n      <td>59.3</td>\n      <td>83.6</td>\n    </tr>\n    <tr>\n      <th>XLM-R Base</th>\n      <td>81.2</td>\n      <td>23.4</td>\n      <td>61.1</td>\n      <td>52.8</td>\n      <td>61.1</td>\n      <td>33.8</td>\n      <td>58.2</td>\n      <td>45.7</td>\n      <td>46.9</td>\n      <td>61.8</td>\n      <td>52.1</td>\n      <td>62.4</td>\n    </tr>\n    <tr>\n      <th>MAD-X</th>\n      <td>83.3</td>\n      <td>66.8</td>\n      <td>74.0</td>\n      <td>71.8</td>\n      <td>75.0</td>\n      <td>68.6</td>\n      <td>74.0</td>\n      <td>68.4</td>\n      <td>67.8</td>\n      <td>73.2</td>\n      <td>65.9</td>\n      <td>76.6</td>\n    </tr>\n    <tr>\n      <th>Our Method</th>\n      <td>83.6</td>\n      <td>67.9</td>\n      <td>76.1</td>\n      <td>73.1</td>\n      <td>75.9</td>\n      <td>69.2</td>\n      <td>75.0</td>\n      <td>69.2</td>\n      <td>69.0</td>\n      <td>73.8</td>\n      <td>66.7</td>\n      <td>78.9</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "               en    ar    de    el    es    hi    ru    th    tr    vi    zh  \\\nmBERT        83.5  61.5  70.6  62.6  75.5  59.2  71.3  42.7  55.4  69.5  58.0   \nXLM-R Large  86.5  68.6  80.4  79.8  82.0  76.7  80.1  74.2  75.9  79.1  59.3   \nXLM-R Base   81.2  23.4  61.1  52.8  61.1  33.8  58.2  45.7  46.9  61.8  52.1   \nMAD-X        83.3  66.8  74.0  71.8  75.0  68.6  74.0  68.4  67.8  73.2  65.9   \nOur Method   83.6  67.9  76.1  73.1  75.9  69.2  75.0  69.2  69.0  73.8  66.7   \n\n               ro  \nmBERT        72.7  \nXLM-R Large  83.6  \nXLM-R Base   62.4  \nMAD-X        76.6  \nOur Method   78.9  "
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we add our scores to the dataframe\n",
    "task = \"qa\"\n",
    "for lang in to_test:\n",
    "    if lang in scores[\"qa\"].keys():\n",
    "        result = get_highest(\"qa\", lang)\n",
    "        # qx_df.loc[\"XLM-R Base\", lang] = round(scores[task][lang][\"finetune\"]*100, 1)\n",
    "        qx_df.loc[\"MAD-X\", lang] = round(scores[task][lang][\"baseline_closest_featural\"] * 100, 1)\n",
    "        # qx_df.loc[\"Approximation_method\", lang] = round(scores[task][lang][\"reconstructed_featural\"]*100, 1)\n",
    "        qx_df.loc[\"Our Method\", lang] = round(result[\"Best\"][0] * 100, 1)\n",
    "qx_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7c2b1a2f2ada7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Table to be included in the paper! qa results\n",
    "- Our method is better than finetuning mBERT, and very efficient, extendable to all languages.\n",
    "- Here we take the best approximation method, as discussed in _distance_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8ecbcf1c2e9afa24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T15:03:03.349766600Z",
     "start_time": "2025-05-26T15:03:03.314922900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrrrrrr}\n",
      "\\toprule\n",
      " & en & ar & de & el & es & hi & ru & th & tr & vi & zh & ro \\\\\n",
      "\\midrule\n",
      "mBERT & \\tgrad[81.200][83.500][86.500]{83.5} & \\tgrad[23.400][66.800][68.600]{61.5} & \\tgrad[61.100][74.000][80.400]{70.6} & \\tgrad[52.800][71.800][79.800]{62.6} & \\tgrad[61.100][75.500][82.000]{75.5} & \\tgrad[33.800][68.600][76.700]{59.2} & \\tgrad[58.200][74.000][80.100]{71.3} & \\tgrad[42.700][68.400][74.200]{42.7} & \\tgrad[46.900][67.800][75.900]{55.4} & \\tgrad[61.800][73.200][79.100]{69.5} & \\tgrad[52.100][59.300][66.700]{58.0} & \\tgrad[62.400][76.600][83.600]{72.7} \\\\\n",
      "XLM-R Large & \\tgrad[81.200][83.500][86.500]{86.5} & \\tgrad[23.400][66.800][68.600]{68.6} & \\tgrad[61.100][74.000][80.400]{80.4} & \\tgrad[52.800][71.800][79.800]{79.8} & \\tgrad[61.100][75.500][82.000]{82.0} & \\tgrad[33.800][68.600][76.700]{76.7} & \\tgrad[58.200][74.000][80.100]{80.1} & \\tgrad[42.700][68.400][74.200]{74.2} & \\tgrad[46.900][67.800][75.900]{75.9} & \\tgrad[61.800][73.200][79.100]{79.1} & \\tgrad[52.100][59.300][66.700]{59.3} & \\tgrad[62.400][76.600][83.600]{83.6} \\\\\n",
      "XLM-R Base & \\tgrad[81.200][83.500][86.500]{81.2} & \\tgrad[23.400][66.800][68.600]{23.4} & \\tgrad[61.100][74.000][80.400]{61.1} & \\tgrad[52.800][71.800][79.800]{52.8} & \\tgrad[61.100][75.500][82.000]{61.1} & \\tgrad[33.800][68.600][76.700]{33.8} & \\tgrad[58.200][74.000][80.100]{58.2} & \\tgrad[42.700][68.400][74.200]{45.7} & \\tgrad[46.900][67.800][75.900]{46.9} & \\tgrad[61.800][73.200][79.100]{61.8} & \\tgrad[52.100][59.300][66.700]{52.1} & \\tgrad[62.400][76.600][83.600]{62.4} \\\\\n",
      "MAD-X & \\tgrad[81.200][83.500][86.500]{83.3} & \\tgrad[23.400][66.800][68.600]{66.8} & \\tgrad[61.100][74.000][80.400]{74.0} & \\tgrad[52.800][71.800][79.800]{71.8} & \\tgrad[61.100][75.500][82.000]{75.0} & \\tgrad[33.800][68.600][76.700]{68.6} & \\tgrad[58.200][74.000][80.100]{74.0} & \\tgrad[42.700][68.400][74.200]{68.4} & \\tgrad[46.900][67.800][75.900]{67.8} & \\tgrad[61.800][73.200][79.100]{73.2} & \\tgrad[52.100][59.300][66.700]{65.9} & \\tgrad[62.400][76.600][83.600]{76.6} \\\\\n",
      "Our Method & \\tgrad[81.200][83.500][86.500]{83.6} & \\tgrad[23.400][66.800][68.600]{67.9} & \\tgrad[61.100][74.000][80.400]{76.1} & \\tgrad[52.800][71.800][79.800]{73.1} & \\tgrad[61.100][75.500][82.000]{75.9} & \\tgrad[33.800][68.600][76.700]{69.2} & \\tgrad[58.200][74.000][80.100]{75.0} & \\tgrad[42.700][68.400][74.200]{69.2} & \\tgrad[46.900][67.800][75.900]{69.0} & \\tgrad[61.800][73.200][79.100]{73.8} & \\tgrad[52.100][59.300][66.700]{66.7} & \\tgrad[62.400][76.600][83.600]{78.9} \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "# we transform to Latex with the formatters etc.\n",
    "\n",
    "# 1) compute min/median/max per language‐column\n",
    "col_stats = {}\n",
    "for col in qx_df.columns:\n",
    "    vals = qx_df[col].dropna().astype(float)\n",
    "    mn, md, mx = vals.min(), float(np.median(vals)), vals.max()\n",
    "    col_stats[col] = (mn, md, mx)\n",
    "\n",
    "# 2) build a formatter for each column\n",
    "formatters = {}\n",
    "for col, (mn, md, mx) in col_stats.items():\n",
    "    # bind mn,md,mx into the lambda default args\n",
    "    formatters[col] = (\n",
    "        lambda mn, md, mx: lambda x: (f\"\\\\tgrad[{mn:.3f}][{md:.3f}][{mx:.3f}]{{{x:.1f}}}\" if not pd.isna(x) else \"\")\n",
    "    )(mn, md, mx)\n",
    "\n",
    "# 3) export with column‐wise formatting\n",
    "latex = qx_df.to_latex(\n",
    "    escape=False,  # so our \\tgrad[...] macros are passed through\n",
    "    formatters=formatters,\n",
    ")\n",
    "print(latex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146194f3fc18dcab",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Exact match\n",
    "Model \ten \tar \tde \tel \tes \thi \tru \tth \ttr \tvi \tzh \tro \tavg\n",
    "mBERT \t72.2 \t45.1 \t54.0 \t44.9 \t56.9 \t46.0 \t53.3 \t33.5 \t40.1 \t49.6 \t48.3 \t59.9 \t50.3\n",
    "XLM-R Large \t75.7 \t49.0 \t63.4 \t61.7 \t63.9 \t59.7 \t64.3 \t62.8 \t59.3 \t59.0 \t50.0 \t69.7 \t61.5\n",
    "Translate-train mBERT \t72.2 \t51.1 \t60.7 \t53.0 \t63.1 \t55.4 \t59.7 \t33.5 \t54.8 \t56.2 \t56.6 \t- \t56.0\n",
    "Translate-test BERT-L \t77.1 \t58.8 \t66.7 \t65.5 \t68.4 \t60.1 \t66.7 \t50.0 \t49.6 \t61.5 \t59.1 \t- \t62.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "260c88bae15a7a32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T13:46:31.461994700Z",
     "start_time": "2025-05-26T13:46:31.419760100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>en</th>\n      <th>ar</th>\n      <th>de</th>\n      <th>el</th>\n      <th>es</th>\n      <th>hi</th>\n      <th>ru</th>\n      <th>th</th>\n      <th>tr</th>\n      <th>vi</th>\n      <th>zh</th>\n      <th>ro</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>mBERT</th>\n      <td>72.2</td>\n      <td>45.1</td>\n      <td>54.0</td>\n      <td>44.9</td>\n      <td>56.9</td>\n      <td>46.0</td>\n      <td>53.3</td>\n      <td>33.5</td>\n      <td>40.1</td>\n      <td>49.6</td>\n      <td>48.3</td>\n      <td>59.9</td>\n    </tr>\n    <tr>\n      <th>XLM-R Large</th>\n      <td>75.7</td>\n      <td>49.0</td>\n      <td>63.4</td>\n      <td>61.7</td>\n      <td>63.9</td>\n      <td>59.7</td>\n      <td>64.3</td>\n      <td>62.8</td>\n      <td>59.3</td>\n      <td>59.0</td>\n      <td>50.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Translate-train mBERT</th>\n      <td>72.2</td>\n      <td>51.1</td>\n      <td>60.7</td>\n      <td>53.0</td>\n      <td>63.1</td>\n      <td>55.4</td>\n      <td>59.7</td>\n      <td>33.5</td>\n      <td>54.8</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Translate-test BERT-L</th>\n      <td>77.1</td>\n      <td>58.8</td>\n      <td>66.7</td>\n      <td>65.5</td>\n      <td>68.4</td>\n      <td>60.1</td>\n      <td>66.7</td>\n      <td>50.0</td>\n      <td>49.6</td>\n      <td>61.5</td>\n      <td>59.1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>our_baseline_en</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Approximation_method</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                         en    ar    de    el    es    hi    ru    th    tr  \\\nmBERT                  72.2  45.1  54.0  44.9  56.9  46.0  53.3  33.5  40.1   \nXLM-R Large            75.7  49.0  63.4  61.7  63.9  59.7  64.3  62.8  59.3   \nTranslate-train mBERT  72.2  51.1  60.7  53.0  63.1  55.4  59.7  33.5  54.8   \nTranslate-test BERT-L  77.1  58.8  66.7  65.5  68.4  60.1  66.7  50.0  49.6   \nour_baseline_en         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \nApproximation_method    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n\n                         vi    zh    ro  \nmBERT                  49.6  48.3  59.9  \nXLM-R Large            59.0  50.0   NaN  \nTranslate-train mBERT   NaN   NaN   NaN  \nTranslate-test BERT-L  61.5  59.1   NaN  \nour_baseline_en         NaN   NaN   NaN  \nApproximation_method    NaN   NaN   NaN  "
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xq_em = {\n",
    "    \"mBERT\": [72.2, 45.1, 54.0, 44.9, 56.9, 46.0, 53.3, 33.5, 40.1, 49.6, 48.3, 59.9],\n",
    "    \"XLM-R Large\": [75.7, 49.0, 63.4, 61.7, 63.9, 59.7, 64.3, 62.8, 59.3, 59.0, 50.0],\n",
    "    \"Translate-train mBERT\": [72.2, 51.1, 60.7, 53.0, 63.1, 55.4, 59.7, 33.5, 54.8],\n",
    "    \"Translate-test BERT-L\": [77.1, 58.8, 66.7, 65.5, 68.4, 60.1, 66.7, 50.0, 49.6, 61.5, 59.1],\n",
    "}\n",
    "\n",
    "xq_em_df = pd.DataFrame.from_dict(xq_em, orient=\"index\", columns=to_test)\n",
    "# we add our scores to the dataframe\n",
    "# we add our scores to the dataframe\n",
    "task = \"qa\"\n",
    "for lang in to_test:\n",
    "    if lang in scores[\"qa\"].keys():\n",
    "        result = get_highest(\"qa\", lang)\n",
    "        xq_em_df.loc[\"our_baseline_en\", lang] = scores[task][lang][\"baseline_en\"]\n",
    "        xq_em_df.loc[\"Approximation_method\", lang] = scores[task][lang][\"improved_reconstructed_featural_all\"]\n",
    "        xq_em_df.loc[\"Target language adapter\", lang] = scores[task][lang][\"baseline_closest_featural\"]\n",
    "    else:\n",
    "        xq_em_df.loc[\"our_baseline_en\", lang] = None\n",
    "        xq_em_df.loc[\"Approximation_method\", lang] = None\n",
    "xq_em_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23554bb5e01981d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Kunz & Holstrom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28d7631d1a180d28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T13:55:23.658812100Z",
     "start_time": "2025-05-26T13:55:23.652083500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dd0db5cc69114688",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T14:19:54.875406200Z",
     "start_time": "2025-05-26T14:19:54.862222200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th>Source</th>\n      <th colspan=\"2\" halign=\"left\">Kunz</th>\n      <th colspan=\"3\" halign=\"left\">Ours</th>\n    </tr>\n    <tr>\n      <th>Metric</th>\n      <th>Target</th>\n      <th>English</th>\n      <th>Target</th>\n      <th>English</th>\n      <th>Approximation method</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>zh</th>\n      <td>55.2</td>\n      <td>55.0</td>\n      <td>59.2</td>\n      <td>58.8</td>\n      <td>62.0</td>\n    </tr>\n    <tr>\n      <th>vi</th>\n      <td>55.3</td>\n      <td>54.9</td>\n      <td>57.4</td>\n      <td>59.6</td>\n      <td>59.8</td>\n    </tr>\n    <tr>\n      <th>tr</th>\n      <td>53.1</td>\n      <td>51.9</td>\n      <td>54.6</td>\n      <td>53.6</td>\n      <td>59.0</td>\n    </tr>\n    <tr>\n      <th>id</th>\n      <td>55.7</td>\n      <td>53.6</td>\n      <td>60.8</td>\n      <td>57.4</td>\n      <td>59.6</td>\n    </tr>\n    <tr>\n      <th>et</th>\n      <td>54.1</td>\n      <td>50.7</td>\n      <td>55.6</td>\n      <td>52.4</td>\n      <td>58.4</td>\n    </tr>\n    <tr>\n      <th>sw</th>\n      <td>54.0</td>\n      <td>49.7</td>\n      <td>56.8</td>\n      <td>49.0</td>\n      <td>53.2</td>\n    </tr>\n    <tr>\n      <th>ht</th>\n      <td>51.2</td>\n      <td>48.6</td>\n      <td>52.4</td>\n      <td>42.0</td>\n      <td>48.6</td>\n    </tr>\n    <tr>\n      <th>qu</th>\n      <td>51.4</td>\n      <td>51.2</td>\n      <td>50.8</td>\n      <td>46.8</td>\n      <td>53.6</td>\n    </tr>\n    <tr>\n      <th>Average</th>\n      <td>53.8</td>\n      <td>52.0</td>\n      <td>56.0</td>\n      <td>52.4</td>\n      <td>56.8</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "Source    Kunz           Ours                             \nMetric  Target English Target English Approximation method\nzh        55.2    55.0   59.2    58.8                 62.0\nvi        55.3    54.9   57.4    59.6                 59.8\ntr        53.1    51.9   54.6    53.6                 59.0\nid        55.7    53.6   60.8    57.4                 59.6\net        54.1    50.7   55.6    52.4                 58.4\nsw        54.0    49.7   56.8    49.0                 53.2\nht        51.2    48.6   52.4    42.0                 48.6\nqu        51.4    51.2   50.8    46.8                 53.6\nAverage   53.8    52.0   56.0    52.4                 56.8"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data for XLM-R results on COPA\n",
    "data = {\n",
    "    \"Target\": [55.2, 55.3, 53.1, 55.7, 54.1, 54.0, 51.2, 51.4, 53.8],\n",
    "    \"English\": [55.0, 54.9, 51.9, 53.6, 50.7, 49.7, 48.6, 51.2, 52.0],\n",
    "    \"None\": [54.3, 55.1, 51.2, 53.4, 52.3, 52.0, 50.6, 49.6, 52.3],\n",
    "    \"Nonetr\": [49.4, 52.8, 49.3, 49.8, 51.4, 49.7, 49.6, 50.2, 50.3],\n",
    "}\n",
    "\n",
    "index = [\"zh\", \"vi\", \"tr\", \"id\", \"et\", \"sw\", \"ht\", \"qu\", \"Average\"]\n",
    "\n",
    "# Create DataFrame\n",
    "df_xlmr = pd.DataFrame(data, index=index)\n",
    "# we drop \"None\" and \"Nonetr\"\n",
    "df_xlmr.drop(columns=[\"None\", \"Nonetr\"], inplace=True)\n",
    "# we add a column for our COPA scores, for each of the languages\n",
    "task = \"copa\"\n",
    "for lang in index:\n",
    "    if lang in scores[task].keys():\n",
    "        result = get_highest(task, lang)\n",
    "        df_xlmr.loc[lang, \"our_target\"] = round(scores[task][lang][\"baseline_closest_featural\"], 3) * 100\n",
    "        df_xlmr.loc[lang, \"our_baseline_en\"] = round(scores[task][lang][\"baseline_en\"], 3) * 100\n",
    "        df_xlmr.loc[lang, \"Approximation_method\"] = round(result[\"Best\"][0], 3) * 100\n",
    "\n",
    "    else:\n",
    "        df_xlmr.loc[lang, \"our_baseline_en\"] = None\n",
    "        df_xlmr.loc[lang, \"Approximation_method\"] = None\n",
    "# we add the \"Average\" row for our scores\n",
    "df_xlmr.loc[\"Average\", \"our_baseline_en\"] = round(df_xlmr[\"our_baseline_en\"].mean(), 1)\n",
    "df_xlmr.loc[\"Average\", \"Approximation_method\"] = round(df_xlmr[\"Approximation_method\"].mean(), 1)\n",
    "df_xlmr.loc[\"Average\", \"our_target\"] = round(df_xlmr[\"our_target\"].mean(), 1)\n",
    "# define new MultiIndex for the columns\n",
    "df_xlmr.columns = pd.MultiIndex.from_tuples(\n",
    "    [\n",
    "        (\"Kunz\", \"Target\"),\n",
    "        (\"Kunz\", \"English\"),\n",
    "        (\"Ours\", \"our_target\"),\n",
    "        (\"Ours\", \"our_baseline_en\"),\n",
    "        (\"Ours\", \"Approximation_method\"),\n",
    "    ],\n",
    "    names=[\"Source\", \"Metric\"],\n",
    ")\n",
    "df_xlmr.rename(\n",
    "    columns={\"our_baseline_en\": \"English\", \"our_target\": \"Target\", \"Approximation_method\": \"Approximation method\"},\n",
    "    level=\"Metric\",\n",
    "    inplace=True,\n",
    ")\n",
    "df_xlmr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "77113c75039f58be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T14:19:55.385104400Z",
     "start_time": "2025-05-26T14:19:55.370715200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "Source & \\multicolumn{2}{r}{Kunz} & \\multicolumn{3}{r}{Ours} \\\\\n",
      "Metric & Target & English & Target & English & Approximation method \\\\\n",
      "\\midrule\n",
      "zh & \\tgrad[55.000][58.800][62.000]{55.200} & \\tgrad[55.000][58.800][62.000]{55.000} & \\tgrad[55.000][58.800][62.000]{59.200} & \\tgrad[55.000][58.800][62.000]{58.800} & \\tgrad[55.000][58.800][62.000]{62.000} \\\\\n",
      "vi & \\tgrad[54.900][57.400][59.800]{55.300} & \\tgrad[54.900][57.400][59.800]{54.900} & \\tgrad[54.900][57.400][59.800]{57.400} & \\tgrad[54.900][57.400][59.800]{59.600} & \\tgrad[54.900][57.400][59.800]{59.800} \\\\\n",
      "tr & \\tgrad[51.900][53.600][59.000]{53.100} & \\tgrad[51.900][53.600][59.000]{51.900} & \\tgrad[51.900][53.600][59.000]{54.600} & \\tgrad[51.900][53.600][59.000]{53.600} & \\tgrad[51.900][53.600][59.000]{59.000} \\\\\n",
      "id & \\tgrad[53.600][57.400][60.800]{55.700} & \\tgrad[53.600][57.400][60.800]{53.600} & \\tgrad[53.600][57.400][60.800]{60.800} & \\tgrad[53.600][57.400][60.800]{57.400} & \\tgrad[53.600][57.400][60.800]{59.600} \\\\\n",
      "et & \\tgrad[50.700][54.100][58.400]{54.100} & \\tgrad[50.700][54.100][58.400]{50.700} & \\tgrad[50.700][54.100][58.400]{55.600} & \\tgrad[50.700][54.100][58.400]{52.400} & \\tgrad[50.700][54.100][58.400]{58.400} \\\\\n",
      "sw & \\tgrad[49.000][53.200][56.800]{54.000} & \\tgrad[49.000][53.200][56.800]{49.700} & \\tgrad[49.000][53.200][56.800]{56.800} & \\tgrad[49.000][53.200][56.800]{49.000} & \\tgrad[49.000][53.200][56.800]{53.200} \\\\\n",
      "ht & \\tgrad[42.000][48.600][52.400]{51.200} & \\tgrad[42.000][48.600][52.400]{48.600} & \\tgrad[42.000][48.600][52.400]{52.400} & \\tgrad[42.000][48.600][52.400]{42.000} & \\tgrad[42.000][48.600][52.400]{48.600} \\\\\n",
      "qu & \\tgrad[46.800][51.200][53.600]{51.400} & \\tgrad[46.800][51.200][53.600]{51.200} & \\tgrad[46.800][51.200][53.600]{50.800} & \\tgrad[46.800][51.200][53.600]{46.800} & \\tgrad[46.800][51.200][53.600]{53.600} \\\\\n",
      "Average & \\tgrad[52.000][53.800][56.800]{53.800} & \\tgrad[52.000][53.800][56.800]{52.000} & \\tgrad[52.000][53.800][56.800]{56.000} & \\tgrad[52.000][53.800][56.800]{52.400} & \\tgrad[52.000][53.800][56.800]{56.800} \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "# 0) (Optional) escape underscores in your XLM-R columns if present\n",
    "#    — only needed if any metric name contains '_' and you want it literal in LaTeX\n",
    "import numpy as np\n",
    "\n",
    "df_for_latex = df_xlmr.copy()\n",
    "\"\"\" We want row-wise stats instead!\n",
    "# 1) Compute per-column stats on df_for_latex \n",
    "col_stats = {}\n",
    "for col in df_for_latex.columns:\n",
    "    vals = df_for_latex[col].dropna().astype(float)\n",
    "    mn, md, mx = vals.min(), float(np.median(vals)), vals.max()\n",
    "    col_stats[col] = (mn, md, mx)\n",
    "\n",
    "# 2) Build your formatters dict using exactly the same MultiIndex column keys\n",
    "formatters = {}\n",
    "for col, (mn, md, mx) in col_stats.items():\n",
    "    # default-argument trick to bind mn, md, mx at definition time\n",
    "    fmt = lambda x, mn=mn, md=md, mx=mx: (\n",
    "        f\"\\\\tgrad[{mn:.3f}][{md:.3f}][{mx:.3f}]{{{x:.3f}}}\"\n",
    "        if not pd.isna(x) else \"\"\n",
    "    )\n",
    "    formatters[col] = fmt\n",
    "# 3) Export to LaTeX\n",
    "latex_table = df_for_latex.to_latex(\n",
    "    escape=False,        # let \\tgrad[...] pass through\n",
    "    formatters=formatters,\n",
    "    multirow=True\n",
    ")\n",
    "\"\"\"\n",
    "# 1) Compute per-row (min, med, max) stats\n",
    "row_stats = {\n",
    "    idx: (row.min(skipna=True), float(row.median(skipna=True)), row.max(skipna=True))\n",
    "    for idx, row in df_for_latex.astype(float).iterrows()\n",
    "}\n",
    "\n",
    "# 2) Build a new DataFrame of formatted strings\n",
    "formatted = pd.DataFrame(index=df_for_latex.index, columns=df_for_latex.columns, dtype=object)\n",
    "\n",
    "for idx in df_for_latex.index:\n",
    "    mn, md, mx = row_stats[idx]\n",
    "    for col in df_for_latex.columns:\n",
    "        x = df_for_latex.at[idx, col]\n",
    "        if pd.isna(x):\n",
    "            formatted.at[idx, col] = \"\"\n",
    "        else:\n",
    "            formatted.at[idx, col] = f\"\\\\tgrad[{mn:.3f}][{md:.3f}][{mx:.3f}]{{{x:.3f}}}\"\n",
    "# 3) Export the already-formatted table to LaTeX\n",
    "latex_table = formatted.to_latex(\n",
    "    escape=False,  # our macros must pass through\n",
    "    multirow=True,  # if you still want multirow on the first index level\n",
    ")\n",
    "\n",
    "\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4406482da2d907f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
